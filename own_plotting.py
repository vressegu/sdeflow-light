# -*- coding: utf-8 -*-
"""modification of sdeflow_equivalent_sdes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tx_Yt90NRgHve--ocIXi6SGR-0ebwH0N
    associated to https://github.com/CW-Huang/sdeflow-light
"""


import time
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as mticker 
import pandas as pd
from quantitative_comparison import compute_mmd

### 4.1. Define plotting tools
@torch.no_grad()
def get_2d_histogram_plot(data, val=3, 
                           offset_dimplot=0, 
                          num=64, vmin = 0, vmax=10, 
                          use_grid=False, origin='lower',logscale=True):

    # get data
    x = data[:, offset_dimplot]
    if (offset_dimplot+data.shape[1])<3:
        y = data[:, offset_dimplot+1]
    else:
        y = data[:, offset_dimplot+2]
        val = val/2

    xmin = -val
    xmax = val
    ymin = -val
    ymax = val

    # get histogram
    heatmap, xedges, yedges = np.histogram2d(x, y, range=[[xmin, xmax], [ymin, ymax]], bins=num)
    if logscale:
        heatmap_val = heatmap.copy()  # copy heatmap for vmin calculation
        if (heatmap > heatmap.min()).any():
            vmin = heatmap_val[heatmap > heatmap.min()].min()  # use the minimum value from the heatmap
            vmin /=2
        heatmap = np.log(heatmap + 1e-10)  # log scale for better visibility
        vmin = np.log(vmin)  # adjust vmin for log scale
        vmax = heatmap.max()  # adjust vmax for log scale
    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]

    # plot heatmap
    fig, ax = plt.subplots(figsize=(5, 5))
    im = ax.imshow(heatmap.T, extent=extent, origin=origin, vmin=vmin, vmax=vmax)
    ax.grid(False)
    if use_grid:
        plt.xticks(np.arange(-val, val+1, step=1))
        plt.yticks(np.arange(-val, val+1, step=1))
    else:
        plt.xticks([])
        plt.yticks([])

    # tight
    plt.tight_layout()

    # draw to canvas
    fig.canvas.draw()  # draw the canvas, cache the renderer
    image = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)

    tupl = fig.canvas.get_width_height()[::-1]
    if ( tupl[0]*tupl[1]*4 == image.shape[0] ) :
        image = image.reshape(tupl + (4,))
    else:
        image = image.reshape( (tupl[0]*2,tupl[1]*2,4) )
    # Keep only the first three channels (RGB), discarding the alpha channel
    image = image[:, :, 1:]

    plt.close()
    return image

@torch.no_grad()
def plot_selected_inds(xs, inds, use_xticks=True, use_yticks=True, lmbd = 0.,
                        offset_dimplot=0, 
                        include_t0=False, backward=True, plt_show=True, val=3):
    imgs_ = []
    l_inds = len(inds)
    if backward:
        inds = reversed(inds)
    for ind in inds:
        imgs_ += [get_2d_histogram_plot(xs[ind].to('cpu').numpy(), val,  offset_dimplot=offset_dimplot)]
    img_ = np.concatenate(imgs_, axis=1)

    height, width, _ = img_.shape
    height_per_img = width_per_img = height
    figwidth = 25
    fontsize = 15
    if use_xticks:
        xticks = [0.5*width_per_img + width_per_img*i for i in range(l_inds)]
        if not include_t0:
            xticklabels = [r'$i={:d}$'.format(ind+1) for ind in (inds)]
        else:
            xticklabels = [r'$i={:d}$'.format(ind) for ind in (inds)]
    else:
        xticks, xticklabels = [], []
    if use_yticks:
        yticks = [0.5*height_per_img]
        yticklabels = [r'$\lambda={:.2g}$'.format(lmbd)]
    else:
        yticks, yticklabels = [], []

    fig = plt.figure(figsize=(figwidth, figwidth*height/width))
    ax = fig.add_subplot(111)
    ax.imshow(img_)
    axis_color = 'white' #'white'
    ax.spines['bottom'].set_color(axis_color)
    ax.spines['top'].set_color(axis_color)
    ax.spines['left'].set_color(axis_color)
    ax.spines['right'].set_color(axis_color)
    ax.tick_params(axis='x', colors=axis_color)
    ax.tick_params(axis='y', colors=axis_color)
    plt.xticks(xticks, xticklabels, color='black', fontsize=fontsize)
    plt.yticks(yticks, yticklabels, color='black', fontsize=fontsize)
    if plt_show:
        plt.show(block=False)


@torch.no_grad()
def def_pd(xgen, std_norm, std_test_plot, datatype, 
           dimplot=2, offset_dimplot=0, \
              crop_data_plot=False, plot_crop=3, columns_plot=None):
    
    xgen_plot = std_norm * xgen
    if crop_data_plot:
        boolean_mask = (xgen_plot.abs() < (plot_crop * std_norm * std_test_plot)).all(axis=1)
        print( str( (1 - boolean_mask.sum()/ len(boolean_mask)).item() * 100) + " % of samples outside plot limits")
        xgen_plot = xgen_plot[boolean_mask,:]

    pddatagen = pd.DataFrame(xgen_plot[:,0:dimplot].to('cpu'), columns=columns_plot)

    return pddatagen


@torch.no_grad()
def pairplots(xgen, xtest, std_norm, std_test_plot, datatype, name_simu, 
              dimplot=2, offset_dimplot=0, \
              crop_data_plot=False, plot_crop=3, plot_xlim=3, plot_ref_pdf=False, \
              pdf_theor=None, log_scale_pdf=False, columns_plot=None, \
              plt_show=False, dpi=200, height_seaborn=2.5, ssize=10):

    pddatatest = def_pd(xtest, std_norm, std_test_plot, datatype, 
                        dimplot=dimplot, offset_dimplot=offset_dimplot, \
              crop_data_plot=crop_data_plot, plot_crop=plot_crop, columns_plot=columns_plot)
    pddatagen = def_pd(xgen, std_norm, std_test_plot, datatype, 
                       dimplot=dimplot, offset_dimplot=offset_dimplot, \
              crop_data_plot=crop_data_plot, plot_crop=plot_crop, columns_plot=columns_plot)

    pddata = pd.concat([pddatatest.assign(samples="test"),
                        pddatagen.assign(samples="gen.")])

    palette = {"test": sns.color_palette()[0], "gen.": sns.color_palette()[1]}
    plot_kws = {'alpha': 0.1, "s": ssize, "edgecolor": "none", "rasterized": True}

    # === Replace pairplot with PairGrid ===
    g = sns.PairGrid(pddata, hue="samples",
                    corner=True, height=height_seaborn, aspect=1,
                    palette=palette, diag_sharey=False)

    # lower triangle: scatter like before
    g.map_lower(sns.scatterplot, **plot_kws)

    def diag_plot(x, color=None, label=None, **kws):
        ax = plt.gca()

        if label == "test":
            # compute peak density from TEST values only (NumPy, not torch)
            x_np = np.asarray(x, dtype=np.float64)
            x_np = x_np[np.isfinite(x_np)]
            counts, _ = np.histogram(x_np, bins=80, density=True)
            ymax = float(counts.max()) if counts.size else 0.0

            # draw the test histogram
            sns.histplot(
                x=x, bins=80, stat="density",
                element="step", fill=True, alpha=0.25,
                color=palette["test"], **kws
            )

            # set Y limit for this diagonal axis only
            if log_scale_pdf and (counts > 0).any():
                ymin = counts[counts > 0].min()  # use the minimum value from the heatmap
                # ymin /=2
                # ymin *=8 # for swiss roll
            else:
                ymin = 0
                
            if ymax > 0:
                ax.set_ylim(ymin, 1.05 * ymax)

        elif label == "gen.":
            sns.kdeplot(x=x, color=palette["gen."], lw=1.5, **kws)
        
        if plot_ref_pdf:
            plot_xlim_col = plot_xlim * std_norm[offset_dimplot+0] * std_test_plot[offset_dimplot+0]
            # plot_xlim_col = plot_xlim * std_norm[offset_dimplot+i] * std_test_plot[offset_dimplot+i]
            x_min, x_max = -plot_xlim_col, plot_xlim_col
            xx = torch.linspace(x_min, x_max, 2000)
            pdf_theo = pdf_theor.log_prob(xx).exp()
            pdf_theo /= (pdf_theo.sum() * (xx[1]-xx[0]))  # normalize like a density
            plt.plot(xx,pdf_theo, color=palette["test"], linestyle=':', lw=1.5)

        if log_scale_pdf:
            ax.set_yscale('log')

    g.map_diag(diag_plot)

    # legend like before
    handles = [plt.Line2D([], [], marker='o', linestyle='',
                        color=palette[k], markersize=8, alpha=0.6) for k in ["test", "gen."]]
    labels = ["test", "gen."]
    g.figure.legend(handles=handles, labels=labels, loc='upper right', markerscale=ssize)

    # --- Pass 1: lower triangle only ---
    for i, row in enumerate(g.axes):
        plot_ylim_row = plot_xlim * std_norm[offset_dimplot+i] * std_test_plot[offset_dimplot+i]
        for j, ax in enumerate(row):
            if ax is None:
                continue
            plot_xlim_col = plot_xlim * std_norm[offset_dimplot+j] * std_test_plot[offset_dimplot+j]

            if j < i:  # lower triangle
                ax.set_xlim((-plot_xlim_col, plot_xlim_col))
                ax.set_ylim((-plot_ylim_row,  plot_ylim_row))

    # --- Pass 2: diagonals only ---
    for i in range(len(g.diag_vars)):
        ax = g.axes[i, i]
        if ax is None:
            continue
        var = g.diag_vars[i]
        plot_xlim_col = plot_xlim * std_norm[offset_dimplot+i] * std_test_plot[offset_dimplot+i]

        x_min, x_max = -plot_xlim_col, plot_xlim_col
        ax.set_xlim((x_min, x_max))

    for i, row in enumerate(g.axes):
        for j, ax in enumerate(row):
            if ax is None:
                continue

            nbins = 2
            # reduce the number of ticks
            ax.xaxis.set_major_locator(mticker.MaxNLocator(nbins=nbins))  # max 4 x-ticks
            ax.yaxis.set_major_locator(mticker.MaxNLocator(nbins=nbins))  # max 4 y-ticks

            # remove the "0.0" label but keep the tick itself (gridlines if any)
            def fmt_tick(val, pos):
                if abs(val) < 1e-8:   # close to zero
                    return ""         # empty label
                return f"{val:g}"     # compact formatting

            ax.xaxis.set_major_formatter(mticker.FuncFormatter(fmt_tick))
            ax.yaxis.set_major_formatter(mticker.FuncFormatter(fmt_tick))

    plt.tight_layout()
    if plt_show:
        plt.show(block=False); plt.pause(1)
    name_fig = name_simu + "_multDim.png"
    plt.savefig(name_fig, dpi=dpi)
    if plt_show:
        plt.pause(1)
    plt.close()


@torch.no_grad()
def pairplots_single( xtest, std_norm, std_test_plot, datatype, name_simu, 
                     dimplot=2, offset_dimplot=0, \
            crop_data_plot=False, plot_crop=3, plot_xlim=3, plot_ref_pdf=False, \
            pdf_theor=None, log_scale_pdf=False, columns_plot=None, \
            plt_show=False, dpi=200, height_seaborn=2.5, ssize=10):

    pddatatest = def_pd(xtest, std_norm, std_test_plot, datatype, 
                        dimplot=dimplot, offset_dimplot=offset_dimplot, \
            crop_data_plot=crop_data_plot, plot_crop=plot_crop, columns_plot=columns_plot)
    plot_kws={"s": ssize}
    scatter = sns.pairplot(pddatatest, aspect=1, height=height_seaborn, corner=True,plot_kws=plot_kws)
    for i, row in enumerate(scatter.axes):
        plot_ylim_row = plot_xlim * std_norm[offset_dimplot+i]* std_test_plot[offset_dimplot+i]
        for j, ax in enumerate(row):
            plot_xlim_col = plot_xlim * std_norm[offset_dimplot+j]* std_test_plot[offset_dimplot+j]
            if ax is not None:
                if i == j:  # Diagonal
                    ax.set_xlim((-plot_xlim_col,plot_xlim_col))
                if j < i:  # since corner=True, we only have lower triangle
                    ax.set_xlim((-plot_xlim_col,plot_xlim_col))
                    ax.set_ylim((-plot_ylim_row,plot_ylim_row))
    plt.tight_layout()
    if plt_show:
        plt.show(block=False)   
        plt.pause(0.1)
    plt.savefig("results/" + name_simu + ".png", dpi=dpi)
    plt.close()
    plt.pause(0.1)
    plt.close('all')


def preprocessing(xtest, xs_forward, num_steps_forward, name_simu_root, offset_dimplot,
                  noising_plots, plt_show, folder_results, val_hist, std_norm, std_test_plot, device):
    
    xgen_forward = xs_forward[-1,:,:].to(device)

    # metrics of convergence for the forward SDE
    cov_xtest = torch.cov(xtest.T)
    cov_xgen_forward = torch.cov(xgen_forward.T)
    xgen_forward_var = torch.var(xgen_forward.T,dim=1)
    xgen_forward_var_mean = xgen_forward_var.mean()
    xtest_var = torch.var(xtest.T,dim=1)
    xtest_var_mean = xtest_var.mean()
    # comparaison to cov ot X_inf
    cov_xgen_forward_converged = xtest_var_mean * torch.eye(xtest.shape[1]).to('cpu')
    # since tr(cov)=E||X||^2 is theoretically conserved
    d_cov_xtest = torch.norm(cov_xtest - cov_xgen_forward_converged)/torch.sqrt(xtest.shape[1]*torch.trace(cov_xgen_forward_converged**2))
    d_cov_xgen_forward = torch.norm(cov_xgen_forward - cov_xgen_forward_converged)/torch.sqrt(xtest.shape[1]*torch.trace(cov_xgen_forward_converged**2))
    print("dist cov_xtest to  cov_xgen_forward_converged (dist to  weak white noise)= " + str(d_cov_xtest.item()))
    print("dist cov_xgen_forward  to  cov_xgen_forward_converged = " + str(d_cov_xgen_forward.item()))
    # comparaison to cov of weak white noise (with same variance)
    cov_wwn = xgen_forward_var_mean * torch.eye(xtest.shape[1]).to('cpu')
    d_cov_xgen_forward = torch.norm(cov_xgen_forward - cov_wwn)/torch.sqrt(xtest.shape[1]*torch.trace(cov_wwn**2))
    print("dist cov_xgen_forward  to  weak white noise (w. same var.)= " + str(d_cov_xgen_forward.item()))

    # --- plot ---
    # --- define min/max for shared colorbar ---
    vmin = min(cov_xtest.min(), cov_xgen_forward.min(), cov_xgen_forward_converged.min()).item()
    vmax = max(cov_xtest.max(), cov_xgen_forward.max(), cov_xgen_forward_converged.max()).item()
    fig, axs = plt.subplots(1, 4, figsize=(20, 5))
    im0 = axs[0].imshow(cov_xtest, cmap='viridis', vmin=vmin, vmax=vmax)
    axs[0].set_title("Cov(xtest)")
    axs[0].set_xlabel("Dimension")
    axs[0].set_ylabel("Dimension")
    im1 = axs[1].imshow(cov_xgen_forward, cmap='viridis', vmin=vmin, vmax=vmax)
    axs[1].set_title("Cov(xgen_forward)")
    axs[1].set_xlabel("Dimension")
    im2 = axs[2].imshow(cov_xgen_forward_converged, cmap='viridis', vmin=vmin, vmax=vmax)
    axs[2].set_title("Cov(xgen_forward_converged)")
    axs[2].set_xlabel("Dimension")
    im3 = axs[3].imshow(cov_xgen_forward_converged-cov_xgen_forward, cmap='viridis', vmin=vmin, vmax=vmax)
    axs[3].set_title("Cov(xgen_forward_converged - xgen_forward)")
    axs[3].set_xlabel("Dimension")
    # --- shared colorbar ---
    cbar = fig.colorbar(im0, ax=axs)
    cbar.set_label("Covariance value")
    plt.tight_layout()
    time.sleep(0.5)
    if plt_show:
        plt.show(block=False)
    name_fig = folder_results + "/" + name_simu_root + "_cov.png" 
    plt.savefig(name_fig)
    if plt_show:
        plt.pause(1)
    plt.close()
    plt.close('all')

    # print energy
    energy_xtest = torch.sum((xtest**2),dim=1).mean()
    energy_xgen_forward = torch.sum((xgen_forward**2),dim=1).mean()
    print("energy_xtest = " + str(energy_xtest.item()))
    print("energy_xgen_forward = " + str(energy_xgen_forward.item()))
    print("energy_xgen_forward / energy_xtest = " + str(energy_xgen_forward.item()/energy_xtest.item()))

    # indices to visualize
    fig_step = int(num_steps_forward/8) #4
    if fig_step < 1:
        fig_step = 1
    inds_forward = range(0, num_steps_forward+1, fig_step)
    if (noising_plots):
        plot_selected_inds(xs_forward, inds_forward, \
            use_xticks= True, use_yticks=False, lmbd = 0., \
            offset_dimplot=offset_dimplot,
            include_t0=True, backward=False,
            plt_show=plt_show,
            val=val_hist* std_test_plot[offset_dimplot]) # plot
        time.sleep(0.5)
        if plt_show:
            plt.show(block=False)
        name_fig = folder_results + "/" + name_simu_root + "_Forward.png" 
        plt.savefig(name_fig)
        if plt_show:
            plt.pause(1)
        plt.close()
        plt.close('all')
        
        # Signal and image plots
        prefix_save = folder_results + "/" + name_simu_root + "_Forward"
        plot_signal(xs_forward, inds_forward, prefix_save, 
                    std_norm=std_norm , std_test_plot=std_test_plot,
                    plt_show=plt_show, timeToDuplicate= 0)
        
    
def plot_signal(xs,inds, prefix_save, 
                std_norm , std_test_plot, plt_show=False, timeToDuplicate = None):
    dim = xs[-1,:,:].shape[1]
    nb_samples = 10 if timeToDuplicate is not None else 1
    nb_samples = min((nb_samples, xs.shape[1]))
    if timeToDuplicate == -1:
        timeToDuplicate = xs.shape[0] - 1
    npixelx = np.int32( np.sqrt(dim) )
    factor_caxis = (std_norm * std_test_plot).max()
    if (dim > 4**2):
        if (dim == npixelx**2) and (npixelx >= 16): # can define an image
            print("Plot noisy images")
            # print("inds = " + str(inds))
            for ind in inds:
                if ind == timeToDuplicate and timeToDuplicate is not None:
                    nb_samples_loc = nb_samples
                else:
                    nb_samples_loc = 1
                for id_sample in range(nb_samples_loc):
                    xtt_image = (std_norm * xs[ind,id_sample,:].squeeze()).numpy()
                    xtt_image = xtt_image.reshape(([npixelx,npixelx]),order='F')
                    plots_vort(xtt_image, -factor_caxis, factor_caxis)
                    if plt_show:
                        plt.show(block=False)
                    name_fig = prefix_save + "_imageAtt" + str(ind) \
                        + "_sample" + str(id_sample) + "_.png" 
                    plt.savefig(name_fig)
                    if plt_show:
                        plt.pause(1)
                    plt.close()
                    plt.close('all')
        else:# can define time serie
            print("Plot noisy timeseries")
            time_axis = np.arange(0, dim)
            for ind in inds:
                if ind == timeToDuplicate and timeToDuplicate is not None:
                    nb_samples_loc = nb_samples
                else:
                    nb_samples_loc = 1
                for id_sample in range(nb_samples_loc):
                    xtt_timeserie=(std_norm*xs[ind,id_sample,:].squeeze()).numpy()
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(time_axis, xtt_timeserie)
                    ax.set_title("Noisy sample at step " + str(ind))
                    ax.set_xlabel("time")
                    ax.set_ylabel("Value")
                    ax.set_ylim(-2*factor_caxis, 2*factor_caxis)
                    plt.tight_layout()
                    if plt_show:
                        plt.show(block=False)
                    name_fig = prefix_save + "_timeserieAtt" + str(ind) \
                        + "_sample" + str(id_sample) + "_.png" 
                    plt.savefig(name_fig)
                    if plt_show:
                        plt.pause(1)
                    plt.close()
                    plt.close('all')


def plots_vort(U,vmin=-2,vmax=2):
    # X, Y may be non-uniform → use pcolormesh (respects coordinates)
    fig, axs = plt.subplots(1, 1, figsize=(6, 5), constrained_layout=True)

    # U component
    pcm = axs.pcolormesh(U[-1:0:-1,:], shading='auto', vmin=vmin,vmax=vmax)
    axs.set_title("vorticity (1/s)")
    axs.set_aspect('equal')
    fig.colorbar(pcm, ax=axs)

def postprocessing(inds, i_dims, i_complexitys, i_num_stepss_backward, i_iterations, i_run, MSGM, sampler, \
                   xs, xtest, std_norm, std_test_plot, datatype, name_simu, dimplot, offset_dimplot, \
                   crop_data_plot, plot_crop, plot_xlim, plot_ref_pdf, \
                   pdf_theor, log_scale_pdf, columns_plot, \
                   scatter_plots, denoising_plots, include_t0_reverse, plt_show, dpi, height_seaborn, ssize, \
                   evalmmmd, justLoadmmmd, justLoad, save_results, lmbd, val_hist, device, \
                   mmd_ref, mmd_MSGM,mmd_SGM,max_num_samples_for_mmd):

    xgen = xs[-1,:,:].to(device)

    if save_results and not justLoad:
        np.save(name_simu + ".pt", xgen.clone().detach().cpu().numpy())

    # Identify rows with NaN values
    nan_mask = (torch.isnan(xgen) | (torch.abs(xgen) > 1e3 )).any(dim=1)
    # Count rows with NaN values
    nan_count = nan_mask.sum().item()
    if nan_count > 0:
        print(f"Number of rows with NaN or large value: {nan_count}")
    # Remove rows with NaN values
    xgen = xgen[~nan_mask,:]
    del nan_mask

    if (scatter_plots) and (i_run == 0):
        pairplots(xgen, xtest, std_norm, std_test_plot, datatype, name_simu, dimplot=dimplot, offset_dimplot=offset_dimplot, \
                    crop_data_plot=crop_data_plot, plot_crop=plot_crop, plot_xlim=plot_xlim, plot_ref_pdf=plot_ref_pdf, \
                    pdf_theor=pdf_theor, log_scale_pdf=log_scale_pdf, columns_plot=columns_plot, \
                    plt_show=plt_show, dpi=dpi, height_seaborn=height_seaborn, ssize=ssize)
        
    # Survival function plot
    fig, ax, surv = plot_survival_simple(x=xgen, x_ref=xtest, std_norm=None,
                                        prefix_save=name_simu, plt_show=False,
                                        figsize=(3, 2), tail_frac=0.05, return_survival=True)

    if (denoising_plots) and (i_run == 0):
        plot_selected_inds(xs, inds, True, False, lmbd, 
                            offset_dimplot=offset_dimplot,
                            include_t0=include_t0_reverse, 
                            plt_show=plt_show, 
                            val=val_hist * std_test_plot[offset_dimplot]) # plot
        time.sleep(0.5)
        if plt_show:
            plt.show(block=False)
        name_fig = name_simu + ".png" 
        plt.savefig(name_fig)
        if plt_show:
            plt.pause(1)
        plt.close()
        plt.close('all')

    # Signal and image plots
    prefix_save = name_simu + "_Gen"
    plot_signal(xs, inds, prefix_save, 
                    std_norm=std_norm , std_test_plot=std_test_plot,
                    plt_show=plt_show, timeToDuplicate= -1)
        
    # MMD
    if evalmmmd and not justLoadmmmd:
        num_samples_for_mmd = min([xtest.shape[0],max_num_samples_for_mmd])
        xtest = xtest[0:num_samples_for_mmd-1,:]
        xgen = xgen[0:num_samples_for_mmd-1,:]
        with torch.no_grad():
            x_mmd1 = sampler.sample(xtest.shape[0]).to(device)
            dist_train_to_test = compute_mmd(std_norm * x_mmd1,std_norm * xtest)
            dist = compute_mmd(std_norm * xgen,std_norm * xtest)
        mmd_ref[i_dims, i_complexitys, i_num_stepss_backward,i_iterations,i_run] = dist_train_to_test
        print("MMD train to test = " + str(dist_train_to_test.sqrt().item()))
        print("MSGM = " + str(MSGM))
        print("MMD gen. to test = " + str(dist.sqrt().item()))
        if MSGM:
            mmd_MSGM[i_dims, i_complexitys, i_num_stepss_backward,i_iterations,i_run] = dist
        else:
            mmd_SGM[i_dims, i_complexitys, i_num_stepss_backward,i_iterations,i_run] = dist

"""
survival_simple.py

Simple empirical survival plot for two datasets (test and generated).

Features:
- Accepts torch tensors x (generated) and x_ref (test), shape (N, d).
- Optional per-dimension or scalar scaling `std_norm` (applied before computing norms).
- Computes empirical survival S(R) = P(||x|| > R) on a shared log-spaced R grid.
- Simple log-log linear fit on the tail (ordinary least squares on log S vs log R).
  Tail selection can be controlled with `tail_frac` (fraction of largest observations)
  or explicitly by `tail_k` (number of top order statistics).
- No confidence intervals, no Hill estimator complexity — minimal and fast.
- Compact, paper-ready plotting defaults (suitable for small figures, e.g. figsize=(3,2)).

Usage:
    from survival_simple import plot_survival_simple
    fig, ax, surv = plot_survival_simple(x_gen, x_test, std_norm=std_norm,
                                         prefix_save="sim_surv",
                                         figsize=(3,2),
                                         tail_frac=0.05, tail_k=None,
                                         plt_show=False, return_survival=True)

Returns:
    (fig, ax) or (fig, ax, survival_dict) if return_survival=True

Author: Assistant (statistician)
Date: 2025-12-01
"""
from typing import Optional, Tuple, Dict, Any

import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns


def _compute_common_R_grid(norms_list, n_points: int = 200) -> np.ndarray:
    # Build a shared log-spaced grid from available norms
    mins = []
    maxs = []
    for arr in norms_list:
        if arr is None or len(arr) == 0:
            continue
        pos = arr[arr > 0]
        if pos.size > 0:
            mins.append(pos.min())
        maxs.append(arr.max())
    if len(maxs) == 0:
        raise ValueError("No data provided to build R grid.")
    min_pos = min(mins) if len(mins) > 0 else 1e-12
    max_val = max(maxs)
    upper = max_val if max_val > min_pos else min_pos * 10.0
    return np.logspace(np.log10(min_pos * 0.9), np.log10(upper), num=n_points)


def _empirical_survival_from_norms(norms: np.ndarray, R_grid: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    norms_sorted = np.sort(norms)
    idx = np.searchsorted(norms_sorted, R_grid, side='right')
    counts = norms.size - idx
    S = counts.astype(float) / float(norms.size) if norms.size > 0 else np.zeros_like(R_grid)
    return S, counts


def _apply_std_norm(t: torch.Tensor, std_norm: Optional[torch.Tensor]) -> torch.Tensor:
    if std_norm is None:
        return t
    if not torch.is_tensor(std_norm):
        std_t = torch.as_tensor(std_norm, dtype=t.dtype, device=t.device)
    else:
        std_t = std_norm.to(dtype=t.dtype, device=t.device)
    return t * std_t


def _tail_fit_loglog(R_grid: np.ndarray, S_vals: np.ndarray, norms: np.ndarray,
                     tail_frac: float = 0.05, tail_k: Optional[int] = None) -> Tuple[Optional[float], Optional[int], Optional[np.ndarray]]:
    """
    Fit a line on log-log scale to the tail of the empirical survival.
    Returns (alpha, k_used, S_fit) where alpha is the tail exponent (positive for Pareto: S ~ C R^{-alpha})
    and k_used is the number of top order stats used. S_fit is the fitted survival evaluated on R_grid.
    If fitting is not possible, returns (None, None, None).
    """
    n = norms.size
    if n < 10:
        return None, None, None

    sorted_norms = np.sort(norms)
    if tail_k is None:
        k = max(10, int(np.clip(np.ceil(n * tail_frac), 10, n - 1)))
    else:
        k = int(min(max(1, tail_k), n - 1))

    # threshold = value at which we take the tail (use (n-k)-th order stat)
    threshold = sorted_norms[-k - 1]
    # select R points in grid >= threshold:
    mask = R_grid >= threshold
    if not np.any(mask):
        return None, k, None

    R_tail = R_grid[mask]
    S_tail = S_vals[mask]

    # Only keep positive S_tail entries for log
    positive_mask = S_tail > 0
    if np.sum(positive_mask) < 3:
        return None, k, None

    R_tail = R_tail[positive_mask]
    S_tail = S_tail[positive_mask]

    # linear fit on (log R, log S): log S = a + b log R  => S = exp(a) * R^b
    logR = np.log(R_tail)
    logS = np.log(S_tail)
    b, a = np.polyfit(logR, logS, 1)  # slope b, intercept a
    # For Pareto-like tail S ~ C * R^{-alpha}, so alpha = -b
    alpha = -b
    S_fit = np.exp(a) * (R_grid ** b)
    return float(alpha), int(k), S_fit


def plot_survival_simple(x: Optional[torch.Tensor] = None,
                         x_ref: Optional[torch.Tensor] = None,
                         std_norm: Optional[torch.Tensor] = None,
                         prefix_save: str = "surv",
                         plt_show: bool = False,
                        #  figsize: Tuple[float, float] = (6, 4),
                         figsize: Tuple[float, float] = (3, 2),
                         n_points: int = 200,
                         tail_frac: float = 0.05,
                         tail_k: Optional[int] = None,
                         colors: Tuple[str, str] = ('#1f77b4', '#ff7f0e'),
                        #  ylim: Tuple[float, float] = (1e-5, 1e1),
                         ylim: Tuple[float, float] = (1e-3, 1.1),
                         save_png: bool = True,
                         return_survival: bool = False,
                         dpi: int = 300) -> Tuple[Any, Any]:
    """
    Simple survival plot for one or two datasets.

    - x_ref is the test/reference dataset (plotted in first color).
    - x is generated dataset (plotted in second color).
    - std_norm (optional) scales each dimension before computing norms (scalar or (d,) vector).
    - tail_frac/tail_k control simple tail selection for the log-log fit.

    Returns (fig, ax) or (fig, ax, survival_dict).
    """
    if x is None and x_ref is None:
        raise ValueError("At least one of x or x_ref must be provided.")

    sns.set_style("whitegrid")
    plt.rcParams.update({
        "font.size": 9,
        "axes.titlesize": 9,
        "axes.labelsize": 9,
        "legend.fontsize": 8,
        "figure.dpi": 150,
    })

    # compute (scaled) norms
    norms_gen = None
    norms_ref = None
    if x_ref is not None:
        assert x_ref.ndim == 2
        xref_scaled = _apply_std_norm(x_ref, std_norm)
        norms_ref = torch.norm(xref_scaled, dim=1).cpu().numpy()
    if x is not None:
        assert x.ndim == 2
        x_scaled = _apply_std_norm(x, std_norm)
        norms_gen = torch.norm(x_scaled, dim=1).cpu().numpy()

    # shared R grid
    R_grid = _compute_common_R_grid([norms_ref, norms_gen], n_points=n_points)

    # empirical survivals
    S_ref = counts_ref = S_gen = counts_gen = None
    if norms_ref is not None:
        S_ref, counts_ref = _empirical_survival_from_norms(norms_ref, R_grid)
    if norms_gen is not None:
        S_gen, counts_gen = _empirical_survival_from_norms(norms_gen, R_grid)

    # simple tail fits
    alpha_ref = k_ref = Sfit_ref = None
    alpha_gen = k_gen = Sfit_gen = None
    if norms_ref is not None:
        alpha_ref, k_ref, Sfit_ref = _tail_fit_loglog(R_grid, S_ref, norms_ref, tail_frac=tail_frac, tail_k=tail_k)
    if norms_gen is not None:
        alpha_gen, k_gen, Sfit_gen = _tail_fit_loglog(R_grid, S_gen, norms_gen, tail_frac=tail_frac, tail_k=tail_k)

    # plotting
    fig, ax = plt.subplots(figsize=figsize)
    ref_color, gen_color = colors

    # plot main curves and create legend entries only for test and gen.
    if S_ref is not None:
        line_ref, = ax.plot(R_grid, S_ref, linestyle='-', color=ref_color, label='test')
    else:
        line_ref = None
    if S_gen is not None:
        # label 'gen.' per your request (with a dot)
        line_gen, = ax.plot(R_grid, S_gen, linestyle='-', color=gen_color, label='gen.')
    else:
        line_gen = None

    # # plot fits but DO NOT add them to the legend
    # if Sfit_ref is not None:
    #     ax.plot(R_grid, Sfit_ref, linestyle='--', color=ref_color, label='_nolegend_')
    # if Sfit_gen is not None:
    #     ax.plot(R_grid, Sfit_gen, linestyle='--', color=gen_color, label='_nolegend_')

    ax.set_xscale('log')
    ax.set_yscale('log')

    # If test/reference provided, fix x limits to the range of the test norms so different
    # generated datasets can be compared on the same horizontal scale.
    if norms_ref is not None:
        pos = norms_ref[norms_ref > 0]
        if pos.size > 0:
            xmin = pos.min() * 0.9
        else:
            xmin = R_grid.min()
        xmax = norms_ref.max()
        # ensure valid positive bounds and a tiny padding if identical
        xmin = max(xmin, 1e-12)
        if xmax <= xmin:
            xmax = xmin * 1.1
        xmax = min(xmax, 1e2)
        ax.set_xlim(xmin, xmax)
    # ax.set_xlim(1e-2, 1e2)

    ax.set_xlabel('R')
    ax.set_ylabel(r"$S(R)=\mathbb{P}\left(\|\mathbf{x}\|>R\right)$")
    ax.grid(True, which='both', linestyle=':', linewidth=0.5, alpha=0.6)

    ymin, ymax = ylim
    ymin = max(ymin, 1e-300)
    ax.set_ylim(ymin, ymax)


    # compact legend inside bottom-left with only two items (test and gen.)
    legend_handles = []
    legend_labels = []
    if line_ref is not None:
        legend_handles.append(line_ref)
        legend_labels.append("test")
    if line_gen is not None:
        legend_handles.append(line_gen)
        legend_labels.append("gen.")
    if len(legend_handles) > 0:
        ax.legend(legend_handles, legend_labels, frameon=False, loc='lower left')


    ax.set_xlabel('R')
    ax.set_ylabel(r"$S(R)=\mathbb{P}\left(\|\mathbf{x}\|>R\right)$")
    ax.grid(True, which='both', linestyle=':', linewidth=0.5, alpha=0.6)

    ymin, ymax = ylim
    ymin = max(ymin, 1e-300)
    ax.set_ylim(ymin, ymax)

    # compact legend inside top-right with only two items (test and gen.)
    legend_handles = []
    legend_labels = []
    if line_ref is not None:
        legend_handles.append(line_ref)
        legend_labels.append("test")
    if line_gen is not None:
        legend_handles.append(line_gen)
        legend_labels.append("gen.")
    if len(legend_handles) > 0:
        ax.legend(legend_handles, legend_labels, frameon=False, loc='lower left', fontsize=7)

    ax.tick_params(axis='both', which='major', labelsize=8)
    plt.tight_layout()

    filename = f"{prefix_save}_survival.png"
    if save_png:
        fig.savefig(filename, bbox_inches='tight', dpi=dpi)

    if plt_show:
        plt.show(block=False)
    else:
        plt.close(fig)

    if return_survival:
        survival_dict = {
            "R_grid": R_grid,
            "reference": {"S": S_ref, "counts": counts_ref, "N": norms_ref.size if norms_ref is not None else 0},
            "generated": {"S": S_gen, "counts": counts_gen, "N": norms_gen.size if norms_gen is not None else 0},
            "fits": {"ref": {"alpha": alpha_ref, "k": k_ref}, "gen": {"alpha": alpha_gen, "k": k_gen}}
        }
        return fig, ax, survival_dict

    return fig, ax


if __name__ == "__main__":
    # quick demo
    torch.manual_seed(0)
    np.random.seed(0)
    N = 20000
    d = 5

    x_gen = torch.randn(N, d)
    x_test = torch.from_numpy(np.random.standard_t(3.0, size=(N, d)).astype(np.float32))

    fig, ax, surv = plot_survival_simple(x=x_gen, x_ref=x_test, std_norm=None,
                                        prefix_save="demo_simple", plt_show=False,
                                        figsize=(3, 2), tail_frac=0.05, return_survival=True)
    print("Saved demo_simple_survival.png")